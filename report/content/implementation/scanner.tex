\section{Scanner}
\label{sec:scannerimplementation}
This section presents our implementation of a scanner for our programming language.

Our scanner takes raw source code in the form of a program written in
\productname{} as input and validates the lexical correctness of a
\productname{} program. It does so by identifying
tokens defined in \productname{} from the input. If an input is met
which cannot be recognized as a valid token, the source code is not
a valid program in \productname{}, hence an exception is thrown and
scanning stops. The exception contains information about the line and
offset at which the input was determined to be incorrect.

The strings which are converted to tokens are called lexemes. Many
lexemes can be converted to the same type of token. Programs will
typically contain many different identifiers, which in \productname{}
will be treated as an \tokenref{ID} token. The name of the identifier will
then be saved as a value belonging to the particular token.

\tab[8cm]{lexemestotokens}{1}{Analysing an input stream for lexemes and tokens.}
                 {		     }
       {Lexemes	}{\textbf{Tokens}    }{
\tabrow{Black 	}{ IDENTIFIER (Black)}
\tabrow{\{    	}{ LBRACE 	     }
\tabrow{Pawn  	}{ IDENTIFIER (Pawn) }
\tabrow{$[$    	}{ LBRACKET	     }
\tabrow{A7    	}{ COORD\_LIT(A7)    }
\tabrow{B7    	}{ COORD\_LIT(B7)    }
\tabrow{C7    	}{ COORD\_LIT(C7)    } 
\tabrow{D7    	}{ COORD\_LIT(D7)    }
\tabrow{E7    	}{ COORD\_LIT(E7)    }
\tabrow{F7    	}{ COORD\_LIT(F7)    }
\tabrow{G7    	}{ COORD\_LIT(G7)    }
\tabrow{H7    	}{ COORD\_LIT(H7)    }
\tabrow{$]$	}{ RBRACKET 	     }
\tabrow{\}    	}{ RBRACE	     }
}

Our scanner consists of two classes: \classref{Scanner} and
\classref{Token}. \classref{Token} contains an instance variable of the 
type \classref{Type} which is an enumerate describing the kind of token.

When a lexeme is found in the input stream, the scanner analyses which
token type it belongs to. A new token is then instantiated and returned
by the scanner. The constructor for \classref{Token} takes the following
arguments: (\classref{Type} \varref{tokenType}, \classref{String} \varref{value}, \classref{int} \textit{line}, \classref{int} \textit{offset}). 
\varref{value} is used in some cases for saving the lexeme the token was made from. For instance, the value of an \tokenref{INT\_LIT} (integer) or the name of an \tokenref{ID} (identifier) must be kept. The \textit{line} and \textit{offset} represent where in the source code the
lexeme of any token was found. This is essential if an error is found,
since it is possible for the scanner to inform the programmer where in
the source code an error exists.

When an input is to be analysed the scanner looks at the first symbol
of the input, which is not a blank or white space character. Based on
the first character met it transfers control to a particular method which is responsible for determining which kind of token that corresponds to the lexeme. This is much easier to implement and maintain rather than having a single, big and clumsy method that handles the conversion from lexeme to token.
This is actually an implementation of an explicitly controlled finite automaton\cite{explicitcontrolledfinitautomaton}. 
The explicit control means that the transitions are handled
``manually'' by transferring control to appropriate methods rather than using a table driven automaton where lookups in a transition table causes a change of state.

In \lstref{lst:scan} you can see many methods named 
\methodref{is{\textit{$\ldots$}}()} for instance \methodref{isDigit()}
and \methodref{isOperator()}. These are the functions which control is 
transferred to when the first character of a lexeme is a digit or a operator. 
If at any time the scanner has reached the end of
the input stream, it returns a \tokenref{EOF} so succeeding parts of the
parser knows where the program ends. 
The method \methodref{isWhitespace()} is simply used to pop all white spaces between lexemes.

Note that a method which the control is transferred to will not always return the same type of token. 
For instance, the method \methodref{scanUppercase()} is responsible
for determining whether the lexeme is a \tokenref{type} or a
\tokenref{coordinate} because they are the only two tokens starting
with an upper case character in \productname{}. This is depicted in
\tableref{table:scanner}. 

\tab[14cm]{scanner}{2}{The different groupings of characters, the method
responsible for handling them and the possible returned token types.}
                         {Action and output					            }
       {First character	}{Responsible function	& Token type				    }{
\tabrow{White space 	}{			& \textit{ignored}			    }
\tabrow{End of file    	}{			& EOF					    }
\tabrow{Digit		}{scanNumeric()		& LIT\_INT				    }
\tabrow{Uppercase    	}{scanUppercase()	& LIT\_COORD, TYPE		 	    }
\tabrow{''		}{scanString()		& LIT\_STRING				    }
\tabrow{\$    		}{scanVar()		& VAR					    }
\tabrow{Operator    	}{scanOperator()	& OP\_PLUS, OP\_MINUS, OP\_MULT,
						  OP\_DIV, OP\_MODULO, OP\_ASSIGN, $\ldots$ }
\tabrow{Lowercase   	}{scanKeyword()		& KEY\_THIS, KEY\_SUPER, KEY\_DEFINE,
						  KEY\_ABSTRACT, KEY\_EXTENDS, $\ldots$	    }
}

Two variables, \classref{int} \varref{offset} and \classref{int}
\varref{line} keep track of where in the source file the next input
character is taken from. If an unexpected input symbol is met, 
a \typeref{SyntaxError} exception is thrown. An
example could be a \$ character followed by white space. \$ is used as
prefix for variables, and expects to be followed by an identifier, e.g.\
\$\varref{varName}. For more information on our error handling, see 
\secref{sec:errorhandling}.
 
\lstinputlisting[caption={The scan() method from the \productname{} scanner.}, label=lst:scan, language=Java]{listings/scan.java}

When a syntactically correct program is accepted by the scanner, a
stream of tokens is created. These tokens are then fed to the parser,
which analyses them and creates an abstract syntax tree of nodes based
on the supplied tokens.
