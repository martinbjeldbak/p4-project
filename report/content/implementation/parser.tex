\section{Parser}

In this section we present our handwritten parser for our programming language.
We have written a top-down recursive descent parser, which is within the class
of LL(1) parsers. The grammar for \productname{} is suited for this because
e.g.\@ it does not have left-recursive productions. This is a result of the
choice of parsing technique before we started formally defining our grammar.

In the end of this section we present our work with SableCC and why we chose not
to continue working with this tool.

\subsection{Constructing the parser}
%structured as the grammar
The parser was very simple to implement, because it is structured in the same
manner as the grammar is defined in EBNF as seen in \secref{sec:grammar}. For
instance if the grammar expresses that the next set of terminals must begin with
a left bracket (`['), then the parser will expect the next token to be a
  \tokenref{LBRACKET} which is the token name for a left bracket. If the grammar
  then expects a non-terminal, then the parser simply calls the method for that
  non-terminal, allowing it to finish, possibly calling more non-terminals and
  expecting terminals, before continuing parsing the next part of the rule.

%discuss the if expression
In \lstref{lst:ifexpr} we give an example of how this structure looks like in
our handwritten parser. The production rule for an if-expression is presented in
\secref{sec:grammar}.

%\begin{ebnf}
%\grule{if\_expr}{\gter{if} \gcat expression \gcat \gter{then} \gcat expression
%\gcat \gter{else} \gcat expression}
%\end{ebnf}

The production for if-expression says that every expression of this type
must start with the combination of the two symbols which spell the word
\gter{if}. When the parser meets this word in an expression, it knows
that it has to parse an if-expression and the code for this is reflected
in \lstref{lst:ifexpr}.

\lstinputlisting[caption="How if-expressions are parsed using top-down parsing in Java.",
label=lst:ifexpr, language=Java]{listings/ifexpr.java}

\subsection{Building an abstract syntax tree}
%astNode()
In \lstref{lst:ifexpr}, the parser initialises the node for the
expected if-expression. The parser starts by calling the method
\methodref{astNode} to create a node for the Abstract Syntax Tree (AST).
We call the method with information about what type of expression this
is (\tokenref{IF\_EXPR}). The method calls the \methodref{expect} method
to verify that the next token is what we are expecting. If the two
tokens do not match, the parser throws a syntax error with information
about the error. If everything is syntactically correct the parser
constructs a node for the AST for the given expression. The first child
of the node is the boolean expression, and the next two siblings of that
child are the expression branches of the if-expression.

\subsubsection{Terminal and nonterminals}
Every grammar has a finite set of nonterminals and terminals that
constitute the productions of the grammar. We have defined tokens in the
parser for every nonterminal in our grammar. The if-expression has the
token name of \tokenref{IF\_EXPR}.

In the production for the if-expression, we have three terminals: the \gter{if},
\gter{then}, and the \gter{else}. These are all required in the method for any
if-expression. When the parser finishes reading a terminal, it knows that the
following token will be an expression, and therefore a new child for the node is
made with a call to the \methodref{expression} method wherein we parse
expressions. Finally the method returns the node containing every child for the
whole if expression.

\subsection{Looking ahead in the input}
%lookAhead methods - atomic
We mentioned earlier that the parser is an LL(1) parser, which means that the
parser is able to look ahead in the sequence of tokens. We have shown the
\methodref{lookAhead} method to determine if the next token is part of an
atomic expression. The production for the atomic expression was presented in
\secref{sec:grammar}.

%\begin{ebnf}
%\grule{atomic}{\gter{(} \gcat expression \gcat \gter{)}}
%\galt{variable}
%\galt{list}
%\galt{\gter{/} \gcat pattern \gcat \gter{/}}
%\galt{\gter{this}}
%\galt{\gter{super}}
%\galt{direction}
%\galt{coordinate}
%\galt{integer}
%\galt{string}
%\galt{type}
%\galt{constant}
%\end{ebnf}

An atomic expression can derive quite a few productions. This is why we have
constructed a specific method to determine whether the next token is part of an
atomic expression. This method is shown in \lstref{lst:lookaheadatomic}.

\lstinputlisting[caption="The lookAhead method to determine if the next
  expression is an atomic type.", label=lst:lookaheadatomic,
language=Java]{listings/method_lookAheadAtomic.java}

The method \methodref{lookAheadAtomic} makes use of two methods to figure out if
the next token is part of an atomic expression. The first method is the
\methodref{lookAhead} method that takes a token as an argument and figures out
if the next token in the sequence of tokens are equal to each other. The second
method is the \methodref{lookAheadLiteral} method which is similar to the method 
in \lstref{lst:lookaheadatomic} but instead of checking for atomic expressions it 
checks for literals. All these methods return true or false.

%example of lookAheadAtomic
%LL(1)
In \lstref{lst:examplelookahead} we show an example of how the
\methodref{lookAhead} method is used in the parser. The example is taken from
the \methodref{expression} method. The productions for expressions are presented
in \secref{sec:grammar}.
The production of an expression is reflected in the code of the parser. An
example of this is given in \lstref{lst:examplelookahead}.

%\begin{ebnf}
%\grule{expression}{assignment}
%\galt{if\_expr}
%\galt{lambda\_expr}
%\galt{\gter{not} \gcat expression}
%\galt{operation}
%\end{ebnf}

\lstinputlisting[caption="Use of the \methodref{lookAhead}-method. This example
is from the \methodref{expression}-method.", label=lst:examplelookahead,
language=Java]{listings/example_lookAheadAtomic.java}

The code presented in \lstref{lst:examplelookahead} is a small section of the
\methodref{expression} method. We have removed code from the section which is
not relevant for the example we are trying to give. The removed code is
presented as \{\ldots\}. In \lstref{lst:examplelookahead} we wish to present how
the \methodref{lookAhead} methods are used.

An assignment begins with the reserved word \gter{let} and the first
\methodref{lookAhead} method peeks for exactly that token to determine
if the next production is an assignment. If the method returns true then
the next token is in fact the \gter{let} word, and the parser enters a
new method, namely the \methodref{assignment} method which checks to
determine if the rest of the production is correctly written. The same
is done for the if expression, lambda expression and operations which
begins with the ``loSequence()'' (logical operators).

The operation production is a bit different, because it needs two lookAhead
methods to determine if the next production is an operation. An operation can
begin with either an atomic value or a minus operator. So the code uses a
\methodref{lookAheadAtomic} and a regular \methodref{lookAhead} with the
specific token as a parameter to check if the next production is an operation.

The methods return nodes which are connected with each other to form
a complete AST\@. When the parser has parsed every token of the input,
it can produce an AST that corresponds to the program written in
\productname{}. This shows that the parser is built systematically
according to the grammar, producing a parse tree consisting of AST
nodes.

\subsection{SableCC}
We have also implemented a scanner and parser using a
compiler/interpreter generator, or a compiler compiler
known as SableCC\cite{sableccdoc}. As described in
\secref{subsec:generatedparsers}, it is an automated scanner and
LALR($1$) parser generator written in Java, with support for making
compilers and interpreters. We have implemented an early version of
\productname{} in SableCC to evaluate the capabilities of such a tool.

\subsubsection{Choice of SableCC}
We chose SableCC instead of various other popular tools such as
ANTLR\cite{antlr} and JavaCC\cite{javacc}. Though ANTLR and JavaCC are far more
well-documented than SableCC, we still chose this tool because it's parser
generates a LALR($1$) parser, whereas ANTLR and JavaCC create simpler
LL($k$) parsers, which our hand-written implementation already takes advantage of.
Therefore, we felt LALR($1$) parsing to be more interesting, since it
also supports more powerful grammars (such as left-recursion).

SableCC outputs an abstract syntax node type fokokr each alternation in
every rule in the grammar specifications file. It's then possible to
iterate over these nodes via extending the visitor pattern SableCC also
supplies, generating code or directly interpreting a syntactically
correct program. This is all done in classes separate from the grammar
specifications, which is also desirable and different from ANTLR
and JavaCC, where action code is injected directly in the grammar
specification. This is all done in Java, which is also desirable, since
it would work well with the rest of the project (also written in Java).

\subsubsection{Experience with SableCC}
Our experience with the tool has been rather cumbersome, in that it took
quite a while to read the documentation before and during writing the
specifications, as it simply isn't just copy/pasting EBNF grammar
into a file. An example of the if-expression rule is seen here

\begin{lstlisting}[caption=Part of the grammar specifications file of SableCC with focus on if-expressions.]
Tokens
  else          = 'else';
  then          = 'then';
  if            = 'if';

Productions
   expression   = {elopexp} element operator expression
                | {assign} assignment
                | {if} if_expr
                | {lambda} lambda_expr
                | {el} element list?
                | {not} not expression;
   if_expr = if [left]:expression then [mid]:expression else [right]:expression;
\end{lstlisting}

% Pros
This example brings out the strengths of SableCC, as it looks very
similar to the EBNF for if-expressions, with a few additions. As long as
you know the special syntax and how helpers, tokens, and productions works, it
is possible to create scanners and parsers very quickly. This was not
our case, as no one had experience with any form of compiler-compilers.
Given that it generates a LALR parser, it grants the ability to have
more powerful grammar than what we had designed. Lastly, the fact that
there's a clear and clean separation between automated, generated code
and user code makes the grammar and compilation/interpretation parts
easier to maintain. When adding new features to the language, you simply
have to update the specifications file and generate a new scanner/parser
combination. On the other hand when adding new features to the language while
using a handwritten scanner and parser many lines of codes needs to be change
in order to implement the new feature. 

% Cons
Even though SableCC looks like a prime candidate to continue
interpretation with, we chose not to use the tool. This is because it
took an unreasonable amount of time to figure out how to precisely
define the grammar to keep it from being ambiguous. And with poor
documentation, it took even longer. Also, it offers less control and
customizability, compared to writing our own from scratch. As an
example, the tool offers an application-specific interface to tree
walking the AST nodes with the visitor pattern, requiring knowledge of
how SableCC implements it. SableCC also generates around 17000 lines of
Java code, even for our simple grammar, which seems superfluous compared
to the handwritten code, consisting of around 1500 lines of code.
%  - Don't learn as much about different parser techniques
%  - Old project, not as active anymore

% WHAT TO CALL THIS SUBSUBSECTION?
\subsubsection{Discussion}
We chose not to continue using SableCC on our updated grammar, due
to the weight of cons against pros, and the fact that the time spent
working on implementing SableCC was also spent making the handwritten
scanner and parser and making them work exactly the way we want them to. It might
not be as easy to modify our language with this solution, but the time
spend on modifying and adding features to our language with the use of a
handwritten scanner and parser is not wasted time, but learning time, which
gives us better understanding of their underlying functionality.  

