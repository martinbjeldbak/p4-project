\subsection{Lexical analysis}
\label{sec:lexicalanalysis}
Before the syntax analysis can be performed a scanner has to perform a lexical analysis. The scanner's job is basicly to check a given source for lexical errors and translating the input stream of characters from the source code into a stream of tokens which the parser can work with \cite[p. 57]{fischer2009} this is done by identifying every lexeme in the source and attaching a potential token to it. Lexemes are strings of characters described by regular expressions. Typical examples of lexemes in a programming language are: variable names, integer literals, operators and special keywords etc. A variable name lexeme could be defined by the following regular expression: $[a-z, A-Z, \"_"][a-z, A-Z, 0-9, \"_"]^*$. Which means a variable name can start with either an uppercase letter, lowercase letter or underscore followed by zero to many lowercase letters, uppercase letters, numbers or underscores. In \tableref{table:lexandtokens} we can see some example of lexemes and the tokens they have been paired up with. If both \textit{a} and \textit{b} are lexemes describing variable names and \textit{102} and \textit{42} are lexemes describing integer literals, then \textit{a} and \textit{b} or \textit{102} and \textit{42} can typically be used interchangeably and still give a syntatic meaningful program. 

A scanner is a relatively simple component which can be constructed by writting it by hand or by using a scanner generator tool such as Lex, which generates an executable scanner by feeding it with a set of regular expressions. When implementing the scanner for \productname{}, we would likely benefit more from crafting the scanner by hand than by using a scanner generator tool, in a learning based perspective. By crafting it by hand, we will know excatly how it's implemented. There might be some advantages of using a scanner generator tool such as the fact that it's more reliable, it's easier to maintain and it's faster to implement if one already know how it works, if not, a handwritten scanner might be just as fast. 

\tab[10cm]{lexandtokens}{1}{Lexemes and their corresponding token group.}
		    {               }
{Lexemes   }{\textbf{Tokens}} {
\tabrow{ x                          }{VAR\_NAME 	  } 
\tabrow{ random\_var\_name          }{VAR\_NAME 	  }
\tabrow{ RANdom\_var\_name2         }{VAR\_NAME 	  }
\tabrow{ 1 						    }{INT\_LITERAL    }
\tabrow{ 342 					    }{INT\_LITERAL    }
\tabrow{ 52890 					    }{INT\_LITERAL    }
\tabrow{ +				 		    }{PLUS\_OPERATOR  }
\tabrow{ - 					 	    }{MINUS\_OPERATOR }
\tabrow{ * 					 	    }{MULT\_OPERATOR  }
\tabrow{ if				 		    }{KEYWORD         }
\tabrow{ while 				        }{KEYWORD  		  }
\tabrow{ switch 				    }{KEYWORD  		  }
}