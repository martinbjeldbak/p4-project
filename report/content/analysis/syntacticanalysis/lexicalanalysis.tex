\subsection{Lexical analysis}
\label{sec:lexicalanalysis}
The lowest level syntactic units of a language is called lexemes. A language's formal description does not often include these. They are instead described by a lexical specification, regular expressions i.e., separated from the syntactic specification\cite[p. 135]{sebesta2013}. Typical lexemes for a programming language includes integer literals, operators and special keywords like \textit{if} and \textit{while}. If both \textit{\$a} and \textit{\$b} are lexemes describing a variable and \textit{102} and \textit{42} are lexemes describing an integer, then \textit{\$a} and \textit{\$b} or \textit{102} and \textit{42} can typically be used interchangeably and still give a meaningful program. Therefore the lexemes are grouped into tokens. The name of a variable or the value of an integer is preserved when tokenising. The tokens are an abstraction that makes it easier to analyse if correct syntax of the language. An example of the grouping of lexemes into tokens can be seen by \tableref{table:lexandtokens}. After the lexical analysis an input stream of characters has been converted to an output stream of tokens.

\tab[4cm]{lexandtokens}{1}{Lexemes and their corresponding token group.}
		    {               }
{Lexemes   }{\textbf{Tokens}}{
\tabrow{\$a}{var(a) 		}
\tabrow{=  }{assign 		}
\tabrow{3  }{int(3) 		}
\tabrow{\$b}{var(b) 		}
\tabrow{+  }{plus   		}
\tabrow{4  }{int(4) 		}
\tabrow{\$a}{var(a) 		}
}